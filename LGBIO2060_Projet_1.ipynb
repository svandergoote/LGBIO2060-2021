{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LGBIO2060_Projet_1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/svandergoote/LGBIO2060-2021/blob/Projet-1/LGBIO2060_Projet_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6sKp_06mJci2"
      },
      "source": [
        "#Projet 1 : Bayesian integration in force estimation\n",
        "Authors : Simon Vandergooten and Clémence Vandamme.\n",
        "\n",
        "In this first project you will have the opportunity to practice what you learned during the exercice sessions. More precisely, you will see how the Bayesian integration can be used in the specific case of force estimation. \n",
        "\n",
        "\n",
        "##Guidelines : \n",
        "\n",
        "1) Read the paper \"*Bayesian integration in force estimation*\" by K. Körding (2004), available on Moodle in the section \"Project\".\n",
        "\n",
        "2) Download the datasets **F_true**, **F_pert** and **delta_y** avalaible on Moodle and store them in the folder of your choice.\n",
        "\n",
        "3) Run the provided cells (Section 1) to import the datasets in Colab.\n",
        "\n",
        "4) Perform the same data analyses as the paper to reproduce **Figure 1D & 2(A $\\rightarrow$ F)**.\n",
        "\n",
        "5) Answer the following questions to check your understanding of the article.\n",
        "\n",
        "* Why is prior knowledge important in general ? How does it help (or not) reducing the errors in this task ? \n",
        "\n",
        "* What is the research question and why is the task suitable to answer it ? \n",
        "\n",
        "* Explain with your own words how the each graphs of figure 2A are obtained. In particular, explain why we expect a linear relationship between dF and F_true if we use full bayesian strategies ? What does the slope represent ? \n",
        "\n",
        "\n",
        "For this project, no report is needed. You will simply drop on moodle one notebook per group. This notebook will contain your entire code (we should be able to generate your figures by running the notebook), the figures, some comments on your methods and the answer of the open questions. The due date is the **28th of October at 23:59**. \n",
        "\n",
        "We will then review together your notebook during a small discussion (10 minutes). You will have the opportunity to explain us more in details what you have done. During this talk, we will also ask you some basic questions to check your understanding of the project. This is not a formal presentation, but it is mandatory.  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J9NhOLHDwtIY"
      },
      "source": [
        "##Some indications\n",
        "\n",
        "First, recall that the Bayes theorem states: \n",
        "\n",
        "$$Posterior \\propto prior * likelihood$$\n",
        "\n",
        "###About the data: \n",
        "\n",
        "After the article reading, take a moment to explore the data structure. The data you have access to are stored in a dictionary `Dict`. In this dictionary, you can then access all subjects (the first 6 subjects belong to group 1, the 5 last belong to group 2). Each subjects entry contains 3 numpy arrays: `F_true`, `F_pert` and `delta_y`. Those arrays are of size (3, 1400). Each line correspond to a day and the is composed of the 7 blocks of 200 trials placed consecutively. \n",
        "\n",
        "Example: You can access the values of the perturbation force for the second subject with `Dict['Sujet 2']['F_pert']`. This will return an numpy array. \n",
        "\n",
        "*Click [here](https://docs.python.org/3/tutorial/datastructures.html) for more context about dictionary (See section 5.5)*.\n",
        "\n",
        "* `F_true` is the true force, the subjects experienced during the first pulse of a trial. As in the paper, it is drawn from two gaussian distribution that differ in their variance. Out of the 11 subjects, the first six experienced the wide distribution for the first two days then the narrow distribution during day 3. It is the opposite for the last five subjects.\n",
        "\n",
        "* `F_pert` is a small perturbation added to the second pulse. It is also gaussian distributed. \n",
        "\n",
        "* `delta_y` is the positional error subjects made with respect to the target. \n",
        "\n",
        "* You can use $c = 0.68 [\\frac{N}{cm}]$\n",
        "\n",
        "Note that these data are not the experimental results of the article. Those are artificial data simulated by us, as we do not have access to the original dataset. Therefore, you will not recover the exact same graphs as the article, but you should obtain similar ones. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBJQZ06smKbI"
      },
      "source": [
        "#Section 1: Import datasets \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77MYO80PNPpd"
      },
      "source": [
        "#import libraries\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "import io\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGFp8hclkEfM",
        "cellView": "form"
      },
      "source": [
        "# @title Run then select the files F_true.csv, F_pert.csv and delta_y.csv on your computer\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fRAzGeJyjNDF",
        "cellView": "form"
      },
      "source": [
        "# @title Run to access and store the datasets\n",
        "F_true = pd.read_csv(io.BytesIO(uploaded['F_true.csv'])).to_numpy()[:,1:]\n",
        "F_pert = pd.read_csv(io.BytesIO(uploaded['F_pert.csv'])).to_numpy()[:,1:]\n",
        "delta_y = pd.read_csv(io.BytesIO(uploaded['F_pert.csv'])).to_numpy()[:,1:]\n",
        "\n",
        "n_subjects = 11\n",
        "n_days = 3\n",
        "Dict = {}\n",
        "\n",
        "for subject in range(n_subjects):\n",
        "  Dict['Sujet ' + str(subject + 1)] = {'F_true':F_true[subject * n_days:(subject + 1) * n_days,:], 'F_pert':F_pert[subject * n_days:(subject + 1) * n_days,:], 'delta_y':delta_y[subject * n_days:(subject + 1) * n_days,:]}\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6VCp166nJFc"
      },
      "source": [
        "You have now access to the dictionary **Dict**.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TdKgD7bCUGmm"
      },
      "source": [
        "#Section 2: Your results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cA7Wz2DIUDqe"
      },
      "source": [
        "#Your contribution starts here :)\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}